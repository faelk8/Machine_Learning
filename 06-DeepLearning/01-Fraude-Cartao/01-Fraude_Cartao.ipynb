{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = '../../dados/creditcard.csv'\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 08:25:54.360306: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-14 08:25:54.362901: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-14 08:25:54.406184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 08:25:55.059230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-14 08:25:55.636172: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-14 08:25:55.636659: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m7,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,777</span> (546.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,777\u001b[0m (546.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=train_features.shape[1:]),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "1781/1781 - 5s - 3ms/step - fn: 235.0000 - fp: 96717.0000 - loss: 6.1057e-06 - precision: 0.0019 - recall: 0.4365 - tn: 130712.0000 - tp: 182.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7765 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 2/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 138.0000 - fp: 144484.0000 - loss: 6.0892e-06 - precision: 0.0019 - recall: 0.6691 - tn: 82945.0000 - tp: 279.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6122 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 3/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 267.0000 - fp: 84976.0000 - loss: 6.1029e-06 - precision: 0.0018 - recall: 0.3597 - tn: 142453.0000 - tp: 150.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7361 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 4/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 212.0000 - fp: 107446.0000 - loss: 6.0984e-06 - precision: 0.0019 - recall: 0.4916 - tn: 119983.0000 - tp: 205.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7384 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 5/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 219.0000 - fp: 116925.0000 - loss: 6.1033e-06 - precision: 0.0017 - recall: 0.4748 - tn: 110504.0000 - tp: 198.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7150 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 6/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 124.0000 - fp: 152150.0000 - loss: 6.0857e-06 - precision: 0.0019 - recall: 0.7026 - tn: 75279.0000 - tp: 293.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.5850 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 7/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 244.0000 - fp: 99409.0000 - loss: 6.1045e-06 - precision: 0.0017 - recall: 0.4149 - tn: 128020.0000 - tp: 173.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6209 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 8/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 287.0000 - fp: 79362.0000 - loss: 6.1033e-06 - precision: 0.0016 - recall: 0.3118 - tn: 148067.0000 - tp: 130.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7077 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 9/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 204.0000 - fp: 125868.0000 - loss: 6.1016e-06 - precision: 0.0017 - recall: 0.5108 - tn: 101561.0000 - tp: 213.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7044 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 10/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 194.0000 - fp: 119074.0000 - loss: 6.1323e-06 - precision: 0.0019 - recall: 0.5348 - tn: 108355.0000 - tp: 223.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7264 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 11/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 149.0000 - fp: 139755.0000 - loss: 6.1149e-06 - precision: 0.0019 - recall: 0.6427 - tn: 87674.0000 - tp: 268.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6184 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 12/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 288.0000 - fp: 83074.0000 - loss: 6.1027e-06 - precision: 0.0016 - recall: 0.3094 - tn: 144355.0000 - tp: 129.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6998 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 13/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 260.0000 - fp: 85089.0000 - loss: 6.0931e-06 - precision: 0.0018 - recall: 0.3765 - tn: 142340.0000 - tp: 157.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7893 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 14/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 139.0000 - fp: 154718.0000 - loss: 6.1020e-06 - precision: 0.0018 - recall: 0.6667 - tn: 72711.0000 - tp: 278.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6578 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 15/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 195.0000 - fp: 115356.0000 - loss: 6.0900e-06 - precision: 0.0019 - recall: 0.5324 - tn: 112073.0000 - tp: 222.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6332 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 16/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 255.0000 - fp: 91998.0000 - loss: 6.1027e-06 - precision: 0.0018 - recall: 0.3885 - tn: 135431.0000 - tp: 162.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7348 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 17/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 135.0000 - fp: 151247.0000 - loss: 6.0950e-06 - precision: 0.0019 - recall: 0.6763 - tn: 76182.0000 - tp: 282.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6330 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 18/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 204.0000 - fp: 114560.0000 - loss: 6.0972e-06 - precision: 0.0019 - recall: 0.5108 - tn: 112869.0000 - tp: 213.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6345 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 19/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 229.0000 - fp: 100115.0000 - loss: 6.0999e-06 - precision: 0.0019 - recall: 0.4508 - tn: 127314.0000 - tp: 188.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6772 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 20/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 226.0000 - fp: 110974.0000 - loss: 6.0790e-06 - precision: 0.0017 - recall: 0.4580 - tn: 116455.0000 - tp: 191.0000 - val_fn: 1.0000 - val_fp: 35466.0000 - val_loss: 0.4457 - val_precision: 0.0021 - val_recall: 0.9867 - val_tn: 21420.0000 - val_tp: 74.0000\n",
      "Epoch 21/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 157.0000 - fp: 143558.0000 - loss: 1.8491e-05 - precision: 0.0018 - recall: 0.6235 - tn: 83871.0000 - tp: 260.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7272 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 22/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 266.0000 - fp: 83892.0000 - loss: 6.1165e-06 - precision: 0.0018 - recall: 0.3621 - tn: 143537.0000 - tp: 151.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7894 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 23/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 148.0000 - fp: 150966.0000 - loss: 6.1421e-06 - precision: 0.0018 - recall: 0.6451 - tn: 76463.0000 - tp: 269.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6487 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 24/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 227.0000 - fp: 109724.0000 - loss: 6.1439e-06 - precision: 0.0017 - recall: 0.4556 - tn: 117705.0000 - tp: 190.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6710 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 25/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 77.0000 - fp: 174339.0000 - loss: 1.0686e-04 - precision: 0.0019 - recall: 0.8153 - tn: 53090.0000 - tp: 340.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7013 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 26/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 198.0000 - fp: 122334.0000 - loss: 6.1391e-06 - precision: 0.0018 - recall: 0.5252 - tn: 105095.0000 - tp: 219.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7046 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 27/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 244.0000 - fp: 88052.0000 - loss: 6.0989e-06 - precision: 0.0020 - recall: 0.4149 - tn: 139377.0000 - tp: 173.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7846 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 28/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 126.0000 - fp: 159968.0000 - loss: 6.1052e-06 - precision: 0.0018 - recall: 0.6978 - tn: 67461.0000 - tp: 291.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7125 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 29/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 215.0000 - fp: 106554.0000 - loss: 7.1795e-06 - precision: 0.0019 - recall: 0.4844 - tn: 120875.0000 - tp: 202.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7468 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 30/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 107.0000 - fp: 170300.0000 - loss: 6.1028e-06 - precision: 0.0018 - recall: 0.7434 - tn: 57129.0000 - tp: 310.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6967 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 31/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 234.0000 - fp: 99006.0000 - loss: 6.0955e-06 - precision: 0.0018 - recall: 0.4388 - tn: 128423.0000 - tp: 183.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7154 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 32/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 180.0000 - fp: 129906.0000 - loss: 6.0963e-06 - precision: 0.0018 - recall: 0.5683 - tn: 97523.0000 - tp: 237.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6413 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 33/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 255.0000 - fp: 90808.0000 - loss: 6.0940e-06 - precision: 0.0018 - recall: 0.3885 - tn: 136621.0000 - tp: 162.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6367 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 34/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 223.0000 - fp: 104822.0000 - loss: 6.0966e-06 - precision: 0.0018 - recall: 0.4652 - tn: 122607.0000 - tp: 194.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7144 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 35/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 195.0000 - fp: 121731.0000 - loss: 7.6971e-06 - precision: 0.0018 - recall: 0.5324 - tn: 105698.0000 - tp: 222.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6806 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 36/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 208.0000 - fp: 108726.0000 - loss: 6.1005e-06 - precision: 0.0019 - recall: 0.5012 - tn: 118703.0000 - tp: 209.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7486 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 37/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 227.0000 - fp: 99776.0000 - loss: 6.0937e-06 - precision: 0.0019 - recall: 0.4556 - tn: 127653.0000 - tp: 190.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7446 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 38/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 187.0000 - fp: 122771.0000 - loss: 6.1008e-06 - precision: 0.0019 - recall: 0.5516 - tn: 104658.0000 - tp: 230.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6332 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 39/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 254.0000 - fp: 92638.0000 - loss: 1.4400e-05 - precision: 0.0018 - recall: 0.3909 - tn: 134791.0000 - tp: 163.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7285 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 40/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 107.0000 - fp: 164168.0000 - loss: 6.0924e-06 - precision: 0.0019 - recall: 0.7434 - tn: 63261.0000 - tp: 310.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6510 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 41/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 235.0000 - fp: 104015.0000 - loss: 6.1040e-06 - precision: 0.0017 - recall: 0.4365 - tn: 123414.0000 - tp: 182.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6941 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 42/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 200.0000 - fp: 129447.0000 - loss: 6.0984e-06 - precision: 0.0017 - recall: 0.5204 - tn: 97982.0000 - tp: 217.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6300 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 43/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 215.0000 - fp: 114739.0000 - loss: 6.0981e-06 - precision: 0.0018 - recall: 0.4844 - tn: 112690.0000 - tp: 202.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6204 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 44/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 191.0000 - fp: 121379.0000 - loss: 6.0982e-06 - precision: 0.0019 - recall: 0.5420 - tn: 106050.0000 - tp: 226.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7296 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 45/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 205.0000 - fp: 127919.0000 - loss: 6.1041e-06 - precision: 0.0017 - recall: 0.5084 - tn: 99510.0000 - tp: 212.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7046 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 46/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 192.0000 - fp: 123423.0000 - loss: 6.0974e-06 - precision: 0.0018 - recall: 0.5396 - tn: 104006.0000 - tp: 225.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7480 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 47/3000\n",
      "1781/1781 - 5s - 3ms/step - fn: 152.0000 - fp: 150774.0000 - loss: 8.7585e-06 - precision: 0.0018 - recall: 0.6355 - tn: 76655.0000 - tp: 265.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6492 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 48/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 262.0000 - fp: 92908.0000 - loss: 6.1026e-06 - precision: 0.0017 - recall: 0.3717 - tn: 134521.0000 - tp: 155.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7300 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 49/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 221.0000 - fp: 107458.0000 - loss: 6.0938e-06 - precision: 0.0018 - recall: 0.4700 - tn: 119971.0000 - tp: 196.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7607 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 50/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 159.0000 - fp: 130692.0000 - loss: 6.0790e-06 - precision: 0.0020 - recall: 0.6187 - tn: 96737.0000 - tp: 258.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7129 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 51/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 207.0000 - fp: 118958.0000 - loss: 6.0994e-06 - precision: 0.0018 - recall: 0.5036 - tn: 108471.0000 - tp: 210.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6633 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 52/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 179.0000 - fp: 127762.0000 - loss: 6.0960e-06 - precision: 0.0019 - recall: 0.5707 - tn: 99667.0000 - tp: 238.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6437 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 53/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 231.0000 - fp: 95948.0000 - loss: 6.0853e-06 - precision: 0.0019 - recall: 0.4460 - tn: 131481.0000 - tp: 186.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7823 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 54/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 210.0000 - fp: 110513.0000 - loss: 6.0961e-06 - precision: 0.0019 - recall: 0.4964 - tn: 116916.0000 - tp: 207.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6585 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 55/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 202.0000 - fp: 121392.0000 - loss: 6.1172e-06 - precision: 0.0018 - recall: 0.5156 - tn: 106037.0000 - tp: 215.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7133 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 56/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 218.0000 - fp: 119999.0000 - loss: 6.1001e-06 - precision: 0.0017 - recall: 0.4772 - tn: 107430.0000 - tp: 199.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7327 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 57/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 197.0000 - fp: 133674.0000 - loss: 6.1012e-06 - precision: 0.0016 - recall: 0.5276 - tn: 93755.0000 - tp: 220.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6944 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 58/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 243.0000 - fp: 93138.0000 - loss: 6.0929e-06 - precision: 0.0019 - recall: 0.4173 - tn: 134291.0000 - tp: 174.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 59/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 201.0000 - fp: 133160.0000 - loss: 6.0985e-06 - precision: 0.0016 - recall: 0.5180 - tn: 94269.0000 - tp: 216.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 60/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 289.0000 - fp: 76672.0000 - loss: 6.1019e-06 - precision: 0.0017 - recall: 0.3070 - tn: 150757.0000 - tp: 128.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6701 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 61/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 220.0000 - fp: 107841.0000 - loss: 6.0988e-06 - precision: 0.0018 - recall: 0.4724 - tn: 119588.0000 - tp: 197.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7496 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 62/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 224.0000 - fp: 110404.0000 - loss: 6.1004e-06 - precision: 0.0017 - recall: 0.4628 - tn: 117025.0000 - tp: 193.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7348 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 63/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 145.0000 - fp: 152944.0000 - loss: 6.0972e-06 - precision: 0.0018 - recall: 0.6523 - tn: 74485.0000 - tp: 272.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6378 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 64/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 256.0000 - fp: 90085.0000 - loss: 6.0902e-06 - precision: 0.0018 - recall: 0.3861 - tn: 137344.0000 - tp: 161.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7095 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 65/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 207.0000 - fp: 121774.0000 - loss: 6.0990e-06 - precision: 0.0017 - recall: 0.5036 - tn: 105655.0000 - tp: 210.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6448 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 66/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 203.0000 - fp: 114218.0000 - loss: 6.0933e-06 - precision: 0.0019 - recall: 0.5132 - tn: 113211.0000 - tp: 214.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6573 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 67/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 238.0000 - fp: 98259.0000 - loss: 6.0942e-06 - precision: 0.0018 - recall: 0.4293 - tn: 129170.0000 - tp: 179.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6934 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 68/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 190.0000 - fp: 120989.0000 - loss: 6.0896e-06 - precision: 0.0019 - recall: 0.5444 - tn: 106440.0000 - tp: 227.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6095 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 69/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 252.0000 - fp: 88410.0000 - loss: 6.0914e-06 - precision: 0.0019 - recall: 0.3957 - tn: 139019.0000 - tp: 165.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6563 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 70/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 226.0000 - fp: 109249.0000 - loss: 6.1003e-06 - precision: 0.0017 - recall: 0.4580 - tn: 118180.0000 - tp: 191.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6837 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 71/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 221.0000 - fp: 116796.0000 - loss: 6.0994e-06 - precision: 0.0017 - recall: 0.4700 - tn: 110633.0000 - tp: 196.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6433 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 72/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 259.0000 - fp: 90088.0000 - loss: 6.0975e-06 - precision: 0.0018 - recall: 0.3789 - tn: 137341.0000 - tp: 158.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7247 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 73/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 205.0000 - fp: 116530.0000 - loss: 6.1015e-06 - precision: 0.0018 - recall: 0.5084 - tn: 110899.0000 - tp: 212.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7228 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 74/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 198.0000 - fp: 128811.0000 - loss: 6.1026e-06 - precision: 0.0017 - recall: 0.5252 - tn: 98618.0000 - tp: 219.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7286 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 75/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 212.0000 - fp: 110905.0000 - loss: 6.0996e-06 - precision: 0.0018 - recall: 0.4916 - tn: 116524.0000 - tp: 205.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7215 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 76/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 215.0000 - fp: 115258.0000 - loss: 6.1031e-06 - precision: 0.0017 - recall: 0.4844 - tn: 112171.0000 - tp: 202.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7009 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 77/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 203.0000 - fp: 114218.0000 - loss: 6.0969e-06 - precision: 0.0019 - recall: 0.5132 - tn: 113211.0000 - tp: 214.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6672 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 78/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 151.0000 - fp: 150390.0000 - loss: 6.0983e-06 - precision: 0.0018 - recall: 0.6379 - tn: 77039.0000 - tp: 266.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6155 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 79/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 259.0000 - fp: 95464.0000 - loss: 6.0958e-06 - precision: 0.0017 - recall: 0.3789 - tn: 131965.0000 - tp: 158.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7414 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 80/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 261.0000 - fp: 95082.0000 - loss: 6.1015e-06 - precision: 0.0016 - recall: 0.3741 - tn: 132347.0000 - tp: 156.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7493 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 81/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 142.0000 - fp: 153197.0000 - loss: 6.0958e-06 - precision: 0.0018 - recall: 0.6595 - tn: 74232.0000 - tp: 275.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6862 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 82/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 219.0000 - fp: 103227.0000 - loss: 6.0964e-06 - precision: 0.0019 - recall: 0.4748 - tn: 124202.0000 - tp: 198.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 83/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 200.0000 - fp: 111399.0000 - loss: 6.0958e-06 - precision: 0.0019 - recall: 0.5204 - tn: 116030.0000 - tp: 217.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6577 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 84/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 249.0000 - fp: 97758.0000 - loss: 6.1071e-06 - precision: 0.0017 - recall: 0.4029 - tn: 129671.0000 - tp: 168.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7292 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 85/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 152.0000 - fp: 146167.0000 - loss: 6.0958e-06 - precision: 0.0018 - recall: 0.6355 - tn: 81262.0000 - tp: 265.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6290 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 86/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 243.0000 - fp: 94545.0000 - loss: 6.1022e-06 - precision: 0.0018 - recall: 0.4173 - tn: 132884.0000 - tp: 174.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6690 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 87/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 203.0000 - fp: 118832.0000 - loss: 6.1000e-06 - precision: 0.0018 - recall: 0.5132 - tn: 108597.0000 - tp: 214.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7093 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 88/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 224.0000 - fp: 101823.0000 - loss: 6.0888e-06 - precision: 0.0019 - recall: 0.4628 - tn: 125606.0000 - tp: 193.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6913 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 89/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 218.0000 - fp: 108479.0000 - loss: 6.1014e-06 - precision: 0.0018 - recall: 0.4772 - tn: 118950.0000 - tp: 199.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7131 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 90/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 238.0000 - fp: 104012.0000 - loss: 6.0998e-06 - precision: 0.0017 - recall: 0.4293 - tn: 123417.0000 - tp: 179.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6880 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 91/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 236.0000 - fp: 107601.0000 - loss: 6.1023e-06 - precision: 0.0017 - recall: 0.4341 - tn: 119828.0000 - tp: 181.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.6959 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 92/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 204.0000 - fp: 119467.0000 - loss: 6.0984e-06 - precision: 0.0018 - recall: 0.5108 - tn: 107962.0000 - tp: 213.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 93/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 202.0000 - fp: 123438.0000 - loss: 6.0964e-06 - precision: 0.0017 - recall: 0.5156 - tn: 103991.0000 - tp: 215.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7078 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 94/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 228.0000 - fp: 99264.0000 - loss: 6.0936e-06 - precision: 0.0019 - recall: 0.4532 - tn: 128165.0000 - tp: 189.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6762 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 95/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 213.0000 - fp: 108852.0000 - loss: 6.0949e-06 - precision: 0.0019 - recall: 0.4892 - tn: 118577.0000 - tp: 204.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6698 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 96/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 185.0000 - fp: 121374.0000 - loss: 6.0932e-06 - precision: 0.0019 - recall: 0.5564 - tn: 106055.0000 - tp: 232.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7169 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 97/3000\n",
      "1781/1781 - 3s - 2ms/step - fn: 239.0000 - fp: 96980.0000 - loss: 6.0987e-06 - precision: 0.0018 - recall: 0.4269 - tn: 130449.0000 - tp: 178.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7757 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n",
      "Epoch 98/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 198.0000 - fp: 120740.0000 - loss: 6.0965e-06 - precision: 0.0018 - recall: 0.5252 - tn: 106689.0000 - tp: 219.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6792 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 99/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 166.0000 - fp: 134788.0000 - loss: 6.0966e-06 - precision: 0.0019 - recall: 0.6019 - tn: 92641.0000 - tp: 251.0000 - val_fn: 75.0000 - val_fp: 0.0000e+00 - val_loss: 0.6430 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 0.0000e+00\n",
      "Epoch 100/3000\n",
      "1781/1781 - 4s - 2ms/step - fn: 282.0000 - fp: 83583.0000 - loss: 6.1040e-06 - precision: 0.0016 - recall: 0.3237 - tn: 143846.0000 - tp: 135.0000 - val_fn: 0.0000e+00 - val_fp: 56886.0000 - val_loss: 0.7257 - val_precision: 0.0013 - val_recall: 1.0000 - val_tn: 0.0000e+00 - val_tp: 75.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x73e1c47259d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
    ")\n",
    "\n",
    "path = '/home/rafael/MEGA/github/Machine_Learning/06-DeepLearning/01-Fraude-Cartao/fraud-best-model/best.weights.h5'\n",
    "\n",
    "# check = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.keras\")]\n",
    "check = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=path,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "early = keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=128,\n",
    "    epochs=3000,\n",
    "    verbose=2,\n",
    "    callbacks=[check,early],\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
